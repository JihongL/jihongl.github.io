<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>python on Meet the Hong</title>
    <link>https://thehong.xyz/categories/python/</link>
    <description>Recent content in python on Meet the Hong</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 24 Oct 2017 17:22:12 +0000</lastBuildDate><atom:link href="https://thehong.xyz/categories/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[파이썬] 주피터 노트북, 셀 결과 모두 출력하기</title>
      <link>https://thehong.xyz/post/python/interactiveshell/</link>
      <pubDate>Tue, 24 Oct 2017 17:22:12 +0000</pubDate>
      
      <guid>https://thehong.xyz/post/python/interactiveshell/</guid>
      <description>주로 주피터 노트북에서 파이썬을 다루고 있는데, print를 따로 해주지 않으면 한 셀마다 마지막 결괏값만 출력되게 된다.
1+2 2*3 2**10 위의 값을 넣고 해당 셀을 실행시키면, 마지막 값인 $2^{10}$ 의 결과인 1024만 출력될 것이다. 하지만 위와 같은 간단한 수식이나 코드를 확인하고자 매번 새로운 셀을 만들어주는 것은 여간 귀찮은 것이 아니다. 이럴 경우 다음 코드를 실행해주면, 한 셀에 입력된 수식과 함수들의 결과가 모두 출력되도록 할 수 있다.
from IPython.core.interactiveshell import InteractiveShell InteractiveShell.ast_node_interactivity = &amp;#34;all&amp;#34; 이제 다시 수식 셀을 실행하면, 각각의 결괏값이 출력된다.</description>
    </item>
    
    <item>
      <title>[파이썬] 네이버 카페 크롤링</title>
      <link>https://thehong.xyz/post/python/naver-crawl/</link>
      <pubDate>Sun, 08 Oct 2017 23:04:25 +0000</pubDate>
      
      <guid>https://thehong.xyz/post/python/naver-crawl/</guid>
      <description>최근에 자연어 처리 프로젝트를 진행할 기회가 있었는데, 그 시작이 네이버 카페 게시글을 크롤링하는 것이었다. 크롤링이야 쉽게 끝날 것으로 생각했었는데 녹록지 않았음. 에러도 없고 몇 번이고 경로를 확인했지만 크롤링이 되질 않았었다. 결국, 네이버 카페가 iframe 구조로 되어있기 때문에 다른 접근을 해야 한다는 것을 알게 되었다.
OSX, Anaconda Python 3.6에 selenium, BeautifulSoup을 사용했다.
기본적인 코드는 아래와 같음.
from selenium import webdriver driver = webdriver.PhantomJS() driver.get(#cafe_url) driver.switch_to_frame(&amp;#39;cafe_main&amp;#39;) page_source = driver.page_source print(page_source) driver.close() switch_to_frame을 해줘야 원하는 작동을 하는 것을 확인할 수 있었다.</description>
    </item>
    
    <item>
      <title>Tensorflow model 저장 및 불러오기</title>
      <link>https://thehong.xyz/post/python/tensorflow-model-saveload/</link>
      <pubDate>Tue, 22 Aug 2017 17:27:59 +0000</pubDate>
      
      <guid>https://thehong.xyz/post/python/tensorflow-model-saveload/</guid>
      <description>딥러닝은 학습시키는 시간이 길다보니, 중간중간 저장과 불러오기가 필수. 이번에는 tflearn을 활용하는 방법을 작성하고자 한다.
모델을 만들 때, model = tflearn.DNN(network, checkpoint_path=&amp;quot;파일명&amp;quot;) 위와 같이 checkpoint_path=를 설정해주면, 코드가 위치한 경로에 지정한 파일명으로 checkpoint가 저장된다.
해당 모델을 다음과 같이 실행하면 한 epoch가 완료될 때마다 파일명.setps로 checkpoint가 생성된다. model.fit(X, Y, batch_size=100, n_epoch=10, run_id=&#39;모델명&#39;, show_metric=True)
예를 들어 10,000개의 데이터를 batch_size 100으로 fit 하게 되면 100 step마다 1 epoch가 끝나게 되고, 파일명.100 (1 epoch) 파일명.200 (2 epoch) 파일명.</description>
    </item>
    
  </channel>
</rss>
