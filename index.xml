<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Meet the Hong</title>
    <link>https://jihongl.github.io/</link>
    <description>Recent content on Meet the Hong</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 28 Jul 2021 18:34:54 +0900</lastBuildDate><atom:link href="https://jihongl.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Jira Service Management 구성기 - Workflows와 Approval</title>
      <link>https://jihongl.github.io/post/jira-workflow/</link>
      <pubDate>Wed, 28 Jul 2021 18:34:54 +0900</pubDate>
      
      <guid>https://jihongl.github.io/post/jira-workflow/</guid>
      <description>몸담은 팀의 업무 범위가 늘어나며 문의가 점점 많아지기 시작했다. 다른 팀에선 이슈가 생겼을 때 누구에게 연락해야 하는지 모르기에 조직도의 가장 아래에 있거나 일면식이 있는 팀원에게 연락하기 마련. 이로 인해 특정 구성원에게 자잘한 업무가 몰리고 커뮤니케이션의 비효율을 초래하기 시작하였다.
다행히도 Jira를 도입한 상태였기에 Jira Service Management를 시작하면 되겠다고 생각, 팀의 Admin을 자처하여 구성하겠노라 선언했다. 글로벌 솔루션이니 쉬운 줄 알았거든. 과거형으로 표현한 것은 당연히 녹록지 않았다는 것. 좋은 말로는 세세한 커스터마이징이 가능한, 다른 말로는 작은 것 하나하나 다 신경 써야 하는 이 녀석을 다루며 당황했던 순간을 까먹기 전에 써두려 한다.</description>
    </item>
    
    <item>
      <title>Getting start Hugo w/ Windows</title>
      <link>https://jihongl.github.io/post/getting-start/</link>
      <pubDate>Tue, 27 Jul 2021 17:20:44 +0900</pubDate>
      
      <guid>https://jihongl.github.io/post/getting-start/</guid>
      <description>이전에 hexo를 활용하여 블로그를 운영하다가 이런저런 핑계로 방치하고 오랜 시간이 지났다. 오랜만에 다시 글을 써보려고 했지만, 사용법을 까먹으니 쉽지 않더라. 이럴 바에 새로 시작하자 마음먹고 찾아보니 최근에는 hugo를 많이 쓴다고. 이런 트렌드엔 올라타는 것이 인지상정이라 바로 시작해본다.
그리고 같은 실수를 반복하지 않기 위해, Windows에서 Hugo를 설정하는 여정을 까먹기 전에 써둔다.
1. Scoop 설치 Hugo가 binary 형태 파일을 제공하기는 하지만, 아무래도 활용하기 불편하여 Scoop을 활용한 설치를 진행했다.
많이 활용하고 있는 Ubuntu나 Mac 환경에서 활용하는 apt나 brew 같은 역할을 한다고 하는데, 이번에 처음 활용해보게 되었음.</description>
    </item>
    
    <item>
      <title>[파이썬] 네이버 카페 크롤링</title>
      <link>https://jihongl.github.io/post/naver-crawl/</link>
      <pubDate>Sun, 08 Oct 2017 23:04:25 +0000</pubDate>
      
      <guid>https://jihongl.github.io/post/naver-crawl/</guid>
      <description>최근에 자연어 처리 프로젝트를 진행할 기회가 있었는데, 그 시작이 네이버 카페 게시글을 크롤링하는 것이었다. 크롤링이야 쉽게 끝날 것으로 생각했었는데 녹록지 않았음. 에러도 없고 몇 번이고 경로를 확인했지만 크롤링이 되질 않았었다. 결국, 네이버 카페가 iframe 구조로 되어있기 때문에 다른 접근을 해야 한다는 것을 알게 되었다.
OSX, Anaconda Python 3.6에 selenium, BeautifulSoup을 사용했다.
기본적인 코드는 아래와 같음.
from selenium import webdriver driver = webdriver.PhantomJS() driver.get(#cafe_url) driver.switch_to_frame(&amp;#39;cafe_main&amp;#39;) page_source = driver.page_source print(page_source) driver.close() switch_to_frame을 해줘야 원하는 작동을 하는 것을 확인할 수 있었다.</description>
    </item>
    
  </channel>
</rss>
